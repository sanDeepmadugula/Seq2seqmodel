{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq Model French To Eng.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mww7nIF9PtnO",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "7dde504b-83a4-44f2-b64f-56512d8206a1"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f2b48aa5-6545-4206-87e6-d0c989950cb4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f2b48aa5-6545-4206-87e6-d0c989950cb4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fra.txt to fra.txt\n",
            "User uploaded file \"fra.txt\" with length 10200867 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygaEAx5QVz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3fc6d75-2a30-419c-f184-b065b860c370"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, CuDNNLSTM, Dense\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNebI9uVRtLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "num_samples = 10000\n",
        "data = 'fra.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Ulu7j6R-o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv(data,delimiter='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2KS0bvKSFVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7c4d0f32-3f44-4bb5-c0ee-23d52d29a375"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Go.</th>\n",
              "      <th>Va !</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Au feu !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Help!</td>\n",
              "      <td>À l'aide !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>Saute.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Ça suffit !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Stop !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Arrête-toi !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>Attends !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Go.          Va !\n",
              "0   Run!       Cours !\n",
              "1   Run!      Courez !\n",
              "2   Wow!    Ça alors !\n",
              "3  Fire!      Au feu !\n",
              "4  Help!    À l'aide !\n",
              "5  Jump.        Saute.\n",
              "6  Stop!   Ça suffit !\n",
              "7  Stop!        Stop !\n",
              "8  Stop!  Arrête-toi !\n",
              "9  Wait!     Attends !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMevsH5STVJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hagMTXLTjbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utl126IdTlpe",
        "colab_type": "text"
      },
      "source": [
        "**Vactorizing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sRhLhV_Tp4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87be9fab-fa59-45be-eb75-6f93742dd897"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "# Loop over lines\n",
        "lines = open(data).read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "  # Input and target are split by tabs\n",
        "    # English TAB French\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    \n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    # Create a set of all unique characters in the input\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "            \n",
        "    # Create a set of all unique output characters\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "\n",
        "\n",
        "    \n",
        "  \n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF8stZYRVLFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "98882a4c-0978-4e32-dd51-42cbe85dd86b"
      },
      "source": [
        "input_characters = sorted(list(input_characters)) # Make sure we achieve the same order in our input chars\n",
        "\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens = len(input_characters) # size of the english alphabate + numbers + signs etc\n",
        "num_decoder_tokens = len(target_characters) # size of the french alpahbate+ numbers, signs etc\n",
        "\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR2F6in5WvIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# workds as similar to tokenizer\n",
        "# the index maps a character to a number\n",
        "input_token_index = {char: i for i, char in enumerate(input_characters)}\n",
        "target_token_index = {char: i for i, char in enumerate(target_characters)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "794M7DJuXC-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccb7266f-50b7-4370-f21b-7d7f40f9dd4b"
      },
      "source": [
        "# Demo character tokenization\n",
        "for c in 'the cat sits on the mat':\n",
        "  print(input_token_index[c], end= ' ')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63 51 48 0 46 44 63 0 62 52 63 62 0 58 57 0 63 51 48 0 56 44 63 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5DCKU_qXOeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "effede01-7db1-4e75-8e96-11fd9e85d80c"
      },
      "source": [
        "max_encoder_seq_length = max([len(txt) for txt in input_texts]) # Get longest sequence length\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length for inputs: 16\n",
            "Max sequence length for outputs: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7hGbpcKXsAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder_input_data is a 3D array of shape (num_pairs, max_english_sentence_length, num_english_characters) \n",
        "# containing a one-hot vectorization of the English sentences.\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32'\n",
        ")\n",
        "\n",
        "# decoder_input_data is a 3D array of shape (num_pairs, max_french_sentence_length, num_french_characters) \n",
        "# containg a one-hot vectorization of the French sentences.\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32'\n",
        ")\n",
        "# decoder_target_data is the same as decoder_input_data but offset by one timestep. \n",
        "# decoder_target_data[:, t, :] will be the same as decoder_input_data[:, t + 1, :]\n",
        "decoder_target_data = np.zeros(\n",
        "\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype= 'float32'\n",
        " )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1IRTG2bZGFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over input texts\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "  # Loop over each char in an input text\n",
        "  for t, char in enumerate(input_text):\n",
        "    \n",
        "    encoder_input_data[i, t, input_token_index[char]] = 1\n",
        "    \n",
        "    for t, char in enumerate(target_text):\n",
        "      \n",
        "      # decoder_target_data is ahead of decoder_input_data by one timestamp\n",
        "      decoder_input_data[i, t, target_token_index[char]] =1\n",
        "      \n",
        "      if t>0:\n",
        "        decoder_target_data[i, t-1, target_token_index[char]]=1\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7iatKLaZ4E1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "035648a8-b690-45d4-88f9-63a882d398a6"
      },
      "source": [
        "# Define input sequence and process it\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens), \n",
        "                       name = 'encoder_inputs')\n",
        "\n",
        "# The return_state contructor argument, configuring a RNN layer to return a list \n",
        "# where the first entry is the outputs and the next entries are the internal RNN states. \n",
        "# This is used to recover the states of the encoder.\n",
        "encoder = CuDNNLSTM(latent_dim, \n",
        "                    return_state=True, \n",
        "                    name = 'encoder')\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens), \n",
        "                       name = 'decoder_inputs')\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = CuDNNLSTM(latent_dim, \n",
        "                         return_sequences=True, \n",
        "                         return_state=True, \n",
        "                         name = 'decoder_lstm')\n",
        "# The inital_state call argument, specifying the initial state(s) of a RNN. \n",
        "# This is used to pass the encoder states to the decoder as initial states.\n",
        "# Basically making the first memory of the decoder the encoded semantics\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, \n",
        "                      activation='softmax', \n",
        "                      name = 'decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 06:34:15.933761 140384830613376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5kP0gjabFZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af1b6ca1-a5a3-4838-b616-8e77d6ddb870"
      },
      "source": [
        "# Run training\n",
        "model.compile(optimizer='rmsprop',\n",
        "             loss='categorical_crossentropy')\n",
        "history = model.fit([encoder_input_data, decoder_input_data],\n",
        "                   decoder_target_data,\n",
        "                   batch_size=batch_size,\n",
        "                   epochs = epochs,\n",
        "                   validation_split = 0.2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 06:36:10.981978 140384830613376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0729 06:36:11.006561 140384830613376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0729 06:36:11.127177 140384830613376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0729 06:36:11.426393 140384830613376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 10s 1ms/step - loss: 0.9274 - val_loss: 0.9817\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.7432 - val_loss: 0.8001\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.6286 - val_loss: 0.7200\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.5722 - val_loss: 0.6641\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.5303 - val_loss: 0.6300\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.4982 - val_loss: 0.6140\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.4730 - val_loss: 0.5886\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.4508 - val_loss: 0.5748\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.4313 - val_loss: 0.5614\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.4137 - val_loss: 0.5415\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3981 - val_loss: 0.5354\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3832 - val_loss: 0.5205\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.3697 - val_loss: 0.5184\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.3569 - val_loss: 0.5146\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.3448 - val_loss: 0.5057\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3336 - val_loss: 0.4983\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3223 - val_loss: 0.4946\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3121 - val_loss: 0.4927\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.3025 - val_loss: 0.4925\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2934 - val_loss: 0.4907\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2840 - val_loss: 0.4872\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2756 - val_loss: 0.4852\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2672 - val_loss: 0.4822\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2597 - val_loss: 0.4865\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2514 - val_loss: 0.4862\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2449 - val_loss: 0.4878\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2375 - val_loss: 0.4864\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2309 - val_loss: 0.4915\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2246 - val_loss: 0.4954\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.2183 - val_loss: 0.4946\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.2121 - val_loss: 0.4979\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2066 - val_loss: 0.5061\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2008 - val_loss: 0.5047\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1959 - val_loss: 0.5104\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1906 - val_loss: 0.5141\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1855 - val_loss: 0.5118\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.1811 - val_loss: 0.5185\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1762 - val_loss: 0.5205\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1719 - val_loss: 0.5259\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1677 - val_loss: 0.5360\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1632 - val_loss: 0.5373\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1594 - val_loss: 0.5428\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1555 - val_loss: 0.5396\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.1522 - val_loss: 0.5506\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1483 - val_loss: 0.5583\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.1450 - val_loss: 0.5626\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1416 - val_loss: 0.5642\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.1383 - val_loss: 0.5711\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1355 - val_loss: 0.5744\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1320 - val_loss: 0.5749\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1291 - val_loss: 0.5839\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.1264 - val_loss: 0.5891\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1236 - val_loss: 0.5911\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1212 - val_loss: 0.6007\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1185 - val_loss: 0.6042\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1161 - val_loss: 0.6084\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1138 - val_loss: 0.6157\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.1117 - val_loss: 0.6115\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.1094 - val_loss: 0.6129\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.1071 - val_loss: 0.6293\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.1049 - val_loss: 0.6324\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.1028 - val_loss: 0.6346\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.1010 - val_loss: 0.6360\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0993 - val_loss: 0.6446\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0970 - val_loss: 0.6481\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.0953 - val_loss: 0.6509\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.0933 - val_loss: 0.6565\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0917 - val_loss: 0.6575\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0902 - val_loss: 0.6632\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0884 - val_loss: 0.6703\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0870 - val_loss: 0.6732\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0855 - val_loss: 0.6776\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0841 - val_loss: 0.6824\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0822 - val_loss: 0.6875\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.0808 - val_loss: 0.6910\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0796 - val_loss: 0.7021\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0781 - val_loss: 0.7009\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0772 - val_loss: 0.7060\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0757 - val_loss: 0.7096\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0744 - val_loss: 0.7137\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.0732 - val_loss: 0.7218\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.0721 - val_loss: 0.7161\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0710 - val_loss: 0.7218\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 2s 210us/step - loss: 0.0698 - val_loss: 0.7295\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0687 - val_loss: 0.7317\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0676 - val_loss: 0.7367\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0666 - val_loss: 0.7408\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0656 - val_loss: 0.7475\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0645 - val_loss: 0.7498\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0636 - val_loss: 0.7492\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.0625 - val_loss: 0.7551\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0617 - val_loss: 0.7598\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.0610 - val_loss: 0.7598\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.0602 - val_loss: 0.7650\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0593 - val_loss: 0.7599\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0585 - val_loss: 0.7701\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0577 - val_loss: 0.7705\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.0567 - val_loss: 0.7738\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.0562 - val_loss: 0.7766\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.0553 - val_loss: 0.7757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJcm2kB2cZWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVVf31vrdlUN",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8B26-7mdnmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "b1237f0a-eae7-42f1-f540-be07d232f68a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "a, = plt.plot(history.history['loss'], label='Training loss')\n",
        "b, = plt.plot(history.history['val_loss'],label='Validation loss')\n",
        "plt.legend(handles = [a,b])\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAGfCAYAAACdqpz+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREpEkUrERERESa5P8B6d9JmL1CPA0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAorJ5s9eA7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD-Yi64reKTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define decoder model\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "\n",
        "# Create a combined memory to input into the decoder\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "\n",
        "    decoder_inputs, initial_state = decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Predict next char\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# The model takes in the encoder memory plus it's own memory as an input and spits out \n",
        "# a prediction plus its own memory to be used for the next char\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
        "                     [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKdwHVa8fAKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to \n",
        "reverse_input_char_index = {i: char for char,\n",
        "                           i in input_token_index.items()}\n",
        "reverse_target_char_index = {i: char for char, i in target_token_index.items()}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrXFN_snfYrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    # Loop untill we recieve a stop sign\n",
        "    while not stop_condition:\n",
        "        # Get output and internal states of the decoder \n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "        \n",
        "        # Get the predicted token (the token with the highest score)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # Get the character belonging to the token\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        # Append char to output\n",
        "        decoded_sentence += sampled_char\n",
        "        \n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "        \n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4I0oJw4hxbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_text = 'Thanks'\n",
        "placeholder = np.zeros((1, len(my_text)+10, num_encoder_tokens))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM8FHy_ujDOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXVXBsGeh-Y2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "77d058c2-1d94-4cdd-9d57-9378fc3970b0"
      },
      "source": [
        "for i, char in enumerate(my_text):\n",
        "  print(i, char, input_token_index[char])\n",
        "  placeholder[0,i,input_token_index[char]] = 1"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 T 38\n",
            "1 h 51\n",
            "2 a 44\n",
            "3 n 57\n",
            "4 k 54\n",
            "5 s 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAyCIKobiLA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "884ee1a0-53f3-427d-d62f-de76e5c0bf82"
      },
      "source": [
        "decode_sequence(placeholder)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Merci !\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHz2mj3siSYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}